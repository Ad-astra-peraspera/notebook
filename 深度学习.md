## 课程

关系型数据库 非关系型数据库

多模态

模式识别

















## 论文

过去三年中，**Transformer** 架构依然主导潮流，并扩展到更多领域。大规模预训练的 **Transformer** 模型（即**基础模型**）在自然语言和计算机视觉中取得了突破，并催生了**提示学习（Prompting）\**技术的热潮。例如，研究者发现仅通过设计合适的提示让语言模型在回答前输出推理步骤（链式思维提示，Chain-of-Thought）就能大幅提高复杂推理任务的表现[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Simply prompting LMs to output,up works like STaR)。同时，多模态Transformer模型受到关注，DeepMind 的 \*\*Flamingo\*\* 模型将视觉和语言融合，实现了少样本跨模态学习，而谷歌的 \*\*Minerva\*\* 模型表明通过在高质量数学语料上预训练，大型语言模型在数学推理上也能取得出色结果；OpenAI 的 \*\*InstructGPT\*\* 则展示了通过人类反馈强化学习（RLHF）微调大型语言模型的效果[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Expect to find a lot,tune large LMs)。Transformer 架构本身也在演进，为了解决长序列建模的效率问题，出现了\**状态空间模型**等新架构（如 ICLR 2022 的 S4），以及引入稀疏注意力和高效长程依赖处理的新方案，以扩展Transformer对长序列的处理能力。

另一大热点架构是**扩散模型（Diffusion Models）**。扩散模型在**生成模型**领域异军突起，被誉为2022年“最火的新秀”，尤其是在文本生成图像领域表现卓越[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Granted%2C if anything deserves the,Google's Imagen%2C or Stable diffusion)。OpenAI 的 DALL·E 2、谷歌的 Imagen、以及开源的 Stable Diffusion 等扩散模型在图像生成的逼真度和多样性上超越了 GAN 等传统方法[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Granted%2C if anything deserves the,Google's Imagen%2C or Stable diffusion)。仅在两年左右时间，扩散模型技术迅速走向成熟，不仅统治了二维静态图像生成，也开始推广到**3D场景合成**、**视频生成**和**分子结构生成**等领域[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=OpenAI's DALL·E 2%2C Google's Imagen%2C,or Stable diffusion)。NeurIPS 2022 的一项杰出工作系统性地分析了扩散模型的设计空间，提出了改进采样、高效训练和模型预处理的方法，使得扩散模型在 CIFAR-10 上以远少于以往的采样步数达到新的生成效果最佳值（FID 1.79），大幅提升了采样效率和生成质量[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=We argue that the theory,trained score)。值得一提的是，最新的扩散模型常结合Transformer作为骨干网络：例如谷歌的 **Imagen** 利用了预训练的大型语言Transformer来编码文本，再通过图像扩散生成模型实现前所未有的高逼真度图像生成，在COCO数据集上达到前所未有的FID 7.27的成绩，甚至在图文对齐上接近真实图像的水平[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=We present Imagen%2C a text,27 on the)[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=diffusion model,text alignment)。这些成果确立了扩散模型在生成任务中的主导地位。

此外，**图神经网络（GNN）\**在过去几年也稳步发展。虽然GNN的关注度不如Transformer或扩散模型那样高，但其影响力在持续扩大[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Equivariances%2C 3D molecule generation%2C Partial,differential equation solving or reasoning)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=achieved celebrity,differential equation solving or reasoning)。GNN通过在模型中显式利用对称性和不变性，为处理非欧几里得结构数据（如图结构、分子结构等）提供了有效框架。这使得GNN在\**药物分子设计**、**偏微分方程求解**、**知识图谱推理**等领域得到应用[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Equivariances%2C 3D molecule generation%2C Partial,differential equation solving or reasoning)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Graph Neural Networks ,to computationally solve Partial Differential)。例如，NeurIPS 2022 提出的 **MACE** 模型通过更高阶的消息传递提高了对原子间作用力场的预测精度[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=4️⃣ MACE%3A Higher Order Equivariant,Fast and Accurate Force Fields)；又如一种**无网格神经PDE求解器**能够在连续空间上预测任意点的解，跨不同分辨率泛化[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=3️⃣ MAgNet%3A Mesh Agnostic Neural,PDE Solver)。总体而言，新型神经网络架构的研究既包括对现有架构（如Transformer）的改进拓展，也包括针对特定数据结构（图、3D等）的专门架构设计，共同推动了深度学习模型能力和适用范围的拓宽。

## 表示学习与自监督学习

**表示学习**，特别是**自监督学习（SSL）**，已成为现代机器学习研究的核心要素之一[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Image)。自监督方法无需人工标注就能从海量数据中学习特征表示，因而在近年获得广泛应用。从2018年BERT在NLP领域引领浪潮开始，计算机视觉在2020年前后也迎来了SimCLR等成功的自监督方法[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Self,with successful techniques like SimCLR)。到2022–2024年，自监督学习几乎“烘焙”进了大多数研究中，用作训练大模型的基础手段[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Image)。

**对比学习**和**生成式自监督**两大范式在这段时间都有所发展。视觉领域在2021年前后通过对比学习（SimCLR、MoCo、BYOL等）已经接近有监督学习精度，而研究显示该方向在ImageNet等标准数据集上的表现已趋于**瓶颈**[lightly.ai](https://www.lightly.ai/blog/self-supervised-learning-trends-and-what-to-expect-in-2023#:~:text=If you look at the,the need for labeled data)[lightly.ai](https://www.lightly.ai/blog/self-supervised-learning-trends-and-what-to-expect-in-2023#:~:text=After this publication%2C new models,achievable only with supervised learning)。因此，新的趋势转向**掩码预测**等方法：受到BERT掩码语言模型启发，学者提出了**Masked Autoencoders (MAE)** 将遮挡部分图像像素并重建的方法应用于图像领域。2022年的研究表明，MAE是一种**可扩展**的自监督视觉学习框架——通过仅让编码器处理可见补丁并用简单解码器重构高掩码比例的图像，可以加速训练（提高3倍以上）且提升精度；基于MAE的大型ViT-Huge模型只用ImageNet-1K预训练就达到了87.8%的Top-1精度，超越了同等数据上的有监督预训练，并展现出良好的扩展性[openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper#:~:text=This paper shows that masked,by 3x or)[openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper#:~:text=more) and improve accuracy,and shows promising scaling behavior)。这一成果证明了**掩码图像建模**的威力。其后，该思路被扩展到视频等领域，例如VideoMAE通过高掩码比例的视频自监督预训练，实现了数据高效的表征学习[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Pretraining video representations on video,Supervised Video Petraining)。

在跨模态表示学习方面，**多模态自监督**成为热点。OpenAI的 **CLIP**（2021）采用图文对比学习，在图像和文本之间学习到统一的嵌入空间，展示了跨模态表示的强大能力。此方向在随后几年继续发酵：Meta提出了 **Data2Vec** 框架，首次用统一的方法同时自监督预训练语音、视觉和文本模型，采用教师-学生策略实现了跨模态的通用表示学习[lightly.ai](https://www.lightly.ai/blog/self-supervised-learning-trends-and-what-to-expect-in-2023#:~:text=specific algorithms and goals vary,language processing%2C and computer vision)。多模态模型被寄予厚望，因为它显示出使用**单一模型**处理多种模态任务的可行性[lightly.ai](https://www.lightly.ai/blog/self-supervised-learning-trends-and-what-to-expect-in-2023#:~:text=Multi,protagonists in shaping the future)[lightly.ai](https://www.lightly.ai/blog/self-supervised-learning-trends-and-what-to-expect-in-2023#:~:text=Self,Data2vec presented for)。例如，ICLR 2023 的 **Socratic Models** 通过组合不同预训练模型的知识，实现了零样本的图像描述和视频问答等多模态推理任务[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=3️⃣ Socratic Models%3A Composing Zero,Multimodal Reasoning with Language)。总体来看，自监督表示学习在图像、文本、语音、视频等各个模态全面开花，不仅方法不断推陈出新，也催生了**基础模型**预训练范式，即在海量无标注数据上学习通用表示，然后迁移到下游任务。在这一过程中，也出现了一些新的认知：DeepMind 在 **Chinchilla** 实验中系统研究了模型大小与训练语料量的权衡，发现许多超大模型其实**欠训练**；更优的策略是在固定计算量下适当减小模型规模、增加训练数据量。基于此训练的70亿参数Chinchilla模型准确率超越了更大的Gopher (2800亿)和GPT-3 (1750亿)等模型[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=1️⃣ An empirical analysis of,Chinchilla)。这一结果强调了**数据规模**对表示学习的关键作用，也为预训练资源分配提供了指南。

## 可扩展性与高效训练方法

随着模型和数据规模在近年急剧增长，**可扩展训练**和**高效计算**成为重要研究方向。**大规模模型的训练**遵循一定的**Scaling Laws（缩放定律）**，即模型误差通常随数据量和参数量呈幂律下降。然而，提升规模意味着巨大的计算开销，因此研究者探索了多种高效训练策略。在模型架构上，引入**稀疏激活**的 **Mixture-of-Experts (MoE)** 是一种重要手段：MoE让模型的大部分参数（专家网络）在每次推理时并非全部激活，而仅为每个输入选择若干专家，从而在固定计算预算下显著提升模型容量。换言之，MoE模型可以用与稠密模型相当的计算量预训练，却支持大得多的参数规模和数据规模，能够更快达到与稠密模型同等的性能[huggingface.co](https://huggingface.co/blog/moe#:~:text=The scale of a model,smaller model for more steps)。Google 的 **Switch Transformer**（2021）就是MoE的代表性成果，它证明了在保持模型质量的前提下，大幅降低专家路由的复杂度，使得训练稳定且高效[medium.com](https://medium.com/@ikim1994914/advanced-modern-llm-part-5-mixture-of-experts-moe-and-switch-transformer-b3d1ce40ced2#:~:text=In the Switch Transformer%2C the,Here’s some additional context)[medium.com](https://medium.com/@ikim1994914/advanced-modern-llm-part-5-mixture-of-experts-moe-and-switch-transformer-b3d1ce40ced2#:~:text=Additionally%2C the authors found that,removed the Gaussian noise addition)。最近的研究继续改进MoE的路由算法和负载均衡，力图在更大规模上部署此类模型[huggingface.co](https://huggingface.co/blog/moe#:~:text=,tuning is promising)[huggingface.co](https://huggingface.co/blog/moe#:~:text=Mixture of Experts enable models,counterpart much faster during pretraining)。

除了架构层面的创新，大模型训练还受益于分布式计算和新的优化算法。比如**ZeRO并行**、**Pipeline并行**等技术将超大模型拆分到多卡乃至多机，提升内存与计算效率。另一方面，**模型压缩**在训练和推理中同样关键：通过**网络剪枝**和**量化**可以削减模型参数量和数值精度，从而降低计算和存储需求。例如，研究者成功在 **物联网微设备** 上进行训练，在仅256KB内存限制下构建了一个端上训练框架[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=used have sufficient power to,evaluate the model’s robustness)。这展示了在极端资源受限环境中执行深度学习的可能。再如，一项NeurIPS 2022工作提出了**数据剪裁（Data Pruning）\**的新思路：与传统的剪枝权重不同，他们在理论和实证上证明，通过\**智能挑选训练样本**，可以打破误差随数据量按幂律缩放的瓶颈，用更少的数据达到相当于使用全部数据训练的效果[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=1️⃣ Beyond neural scaling laws%3A,law scaling via data pruning)。这一结果表明，合理选择数据也许比一味增加数据更有价值[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=1️⃣ Beyond neural scaling laws%3A,law scaling via data pruning)。此外，**个性化联邦学习**、**分布式学习**等也在探索如何在数据不集中的情况下高效协同训练模型[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=On the other hand%2C Federated,1)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=2️⃣ Self)。总的来说，近年围绕高效训练的研究从**算法**（优化方法、稀疏激活）、**数据**（高效利用和筛选）、**系统**（并行计算、内存优化）等多层面共同推进，使得训练更大更复杂的模型成为可能[huggingface.co](https://huggingface.co/blog/moe#:~:text=The scale of a model,smaller model for more steps)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=mainstream real,1)。

## 理论分析：泛化与优化动态

尽管深度学习在实践中大放异彩，对其**理论基础**的探索从未停止。近三年，学界在**泛化**与**优化**理论方面关注诸多关键问题，包括模型在分布迁移下的行为、过参数化情况下的泛化能力、以及训练算法的隐式偏差等。

**出域泛化（Out-of-Domain Generalization, OOD）\**是备受重视的主题之一。随着Imagenet、GLUE等静态测试集被相继“破解”，社区日益关注模型在\**零样本/小样本**设置或**分布显著变化**情况下的稳健表现[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Out,breaking pace)。这带动了对 **因果推理** 与 **不变特征学习** 的研究，希望模型学到更本质的因果结构，从而适应训练分布之外的情形[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=other at a record)。然而，由于OOD问题定义广泛、缺乏统一基准，不同方法难以直接比较。一些工作致力于建立大型基准来系统考察迁移泛化能力[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=2️⃣ Assaying Out,Transfer Learning)。还有方法提出了简单而有效的技巧，例如通过在训练过程中对模型参数做滑动平均并集成多个时刻的模型（无超参数的**平均集成**法），在多个域泛化基准上取得了新的最佳结果，并可用偏差-方差权衡理论解释其有效性[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=1️⃣ Ensemble of Averages%3A Improving,Boosting Performance in Domain Generalization)。

更加基础的理论问题是：**深度模型为何能够泛化**？针对这一“深度学习理论之谜”，许多研究从不同角度给出见解。例如，在NeurIPS 2022中，一篇杰出论文从PAC学习理论角度严格研究了**OOD检测**的可学习性：作者首先给出了OOD检测可学习的必要条件，证明了在某些情况下不存在有效的OOD检测算法，但进一步找到放宽条件后的充分必要条件，刻画了现实场景下OOD检测可以成功的情形，并用该理论解释了一些代表性OOD检测方法为何奏效[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=Supervised learning aims to train,Then%2C using)[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=paper%2C we investigate the probably,Lastly%2C we also offer theoretical)。这项工作为处理训练/测试分布不一致问题提供了坚实的理论基础。又如，有研究从优化景观出发，提出**REPAIR**方法验证了“权重排列不变性”这一神经网络的对称性质：如果消除参数排列带来的差异，可以使两个不同训练所得模型之间实现无障碍的线性插值[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=5️⃣ REPAIR%3A REnormalizing Permuted Activations,for Interpolation Repair)。这解释了为何深度模型的损失景观存在多个平坦谷以及如何在不降性能的情况下在它们之间过渡。

在**优化动态**方面，理论工作同样丰富。一方面，**随机梯度下降（SGD）\**等优化算法的隐式正则化效应受到关注——例如SGD的噪声如何帮助模型逃离陡峭谷底、趋向平坦解，从而提升泛化性能。另一方面，新型优化方法得到理论探析：NeurIPS 2022 的另一篇获奖论文 \*\*“Gradient Descent: The Ultimate Optimizer”\*\* 展示了如何递归地用梯度下降来调整超参数甚至超超参数，只需对反向传播做一个简单修改就能自动计算高阶梯度，实现\**端到端的超参数优化**[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=5️⃣ Gradient Descent%3A The Ultimate,Optimizer)。另外，有理论解释了**对比学习为何需要大批量**：因为在对比自监督中，小批量会导致梯度估计偏差，需要很大批次才能覆盖足够负样本。一项研究从梯度偏差的角度给出了统计解释，并提出贝叶斯数据增广的方法来减轻这种偏差[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=1️⃣ Why do We Need,Bias Perspective)。还有研究关注**非光滑目标的自动微分**、**深度网络的可压缩性与表达能力**等问题，为理解和改进优化算法提供了新见解[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=3️⃣ Automatic differentiation of nonsmooth,iterative algorithms)。

总的来说，理论社区围绕深度学习的一系列基本问题——模型的泛化机制、优化算法的性质、分布外泛化与安全性等——展开了深入探讨，并取得了一些阶段性成果。这些理论进展反过来指导着实践，例如帮助设计更稳健的模型选择策略、启发新的训练算法，以及为深度学习在更广泛环境中的应用奠定基础。

## 应用领域的新进展（NLP、CV、RL）

深度学习在各应用领域的前沿进展同样令人瞩目，不同行业顶会展示了**自然语言处理（NLP）**、**计算机视觉（CV）**、**强化学习（RL）**等方向的创新成果。

- **自然语言处理（NLP）**: 近年NLP领域最大的趋势是**大规模语言模型**及其在各种任务上的泛化能力。GPT-3等百万亿参数级模型（尽管未必以论文形式发表在学术会议）引发了对于**通用人工智能**的讨论。在学术顶会上，大模型相关研究聚焦于提升其**推理能力**和**可控性**。例如，ICLR 2023 的研究提出了*自洽性解码*和*由小到大提示*等改进的推理方法，使大型语言模型在数学推理等复杂任务上表现更佳[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Some of the most insightful,for reasoning in Language Models)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=A new decoding strategy%2C self,boosts on various reasoning benchmarks)。多步推理的提示技巧（如Chain-of-Thought链式思维）已经在NeurIPS 2022等得到验证，可显著提高模型解决算术和常识推理问题的正确率[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Simply prompting LMs to output,up works like STaR)。同时，如何**对齐大语言模型**以遵循人类意图成为焦点，典型方法是**人类反馈强化学习（RLHF）**。OpenAI的InstructGPT工作结合人类偏好对预训练模型进行微调，显著改善了模型的指令遵循能力[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=DeepMind's Flamingo ,tune large LMs)。这类方法在NeurIPS等会议上引起关注，为后来的ChatGPT等系统奠定了基础。此外，多模态NLP模型也在兴起，例如视觉-语言模型**Flamingo**能够从少量示例中学习，同时处理图像和文本输入[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Expect to find a lot,tune large LMs)。另一方向，知识获取与记忆效应也被研究：有工作量化了大模型的**训练数据记忆**，发现模型容量和训练重复对文本片段的记忆程度有显著影响，提出了应对大模型数据隐私泄漏的评估方法[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=4️⃣ Quantifying Memorization Across Neural,Language Models)。整体而言，NLP领域的前沿围绕**更强的泛化推理**（通过提示工程和训练范式改进）以及**更安全可控**的模型（通过对齐和监督信号）在发展。
- **计算机视觉（CV）**: 在视觉领域，**视觉Transformer**架构的普及和自监督预训练使得无监督/少监督学习成为主流。大量Vision Transformer模型在图像分类、检测、分割等任务上超越了以往的CNN方法，特别是配合MAE等自监督算法后表现卓越[openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper#:~:text=more) and improve accuracy,and shows promising scaling behavior)。另一大亮点是**生成模型在视觉上的突破**。扩散模型的成功带来了图像生成质量的飞跃，多项工作达到了前所未有的逼真度。例如，谷歌的Imagen模型结合了大型文本Transformer和扩散生成器，在未使用COCO训练集的情况下生成图像达到了超越以往所有方法的效果[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=We present Imagen%2C a text,27 on the)[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=diffusion model,text alignment)。人类评估也显示Imagen生成的样本在图文对应性和质量上整体优于同时期的CLIP+VQ-GAN、DALL-E 2等模型[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=diffusion model,text alignment)。除了静态图像，**视频生成**也取得进展，ICLR 2023 展示了文本到视频的大模型（如CogVideo）能够生成较连贯的短视频片段[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=4️⃣ CogVideo%3A Large,Video Generation via Transformers)。在计算机视觉应用中，**多模态融合**和**统一建模**也是趋势，比如谷歌提出的 **PaLI** 模型将视觉和语言的多任务预训练相结合，支持图像描述、视觉问答等多种任务[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=The self,Words)。另外，**三维视觉**方面，基于神经辐射场（NeRF）的新方法层出不穷，实现了高保真的新视角合成；NeurIPS等会议也开始出现将Transformer和NeRF结合用于3D重建与生成的工作[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=OpenAI's DALL·E 2%2C Google's Imagen%2C,or Stable diffusion)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=2️⃣ Object Scene Representation Transformer,OSRT)。在实际任务上，深度学习助力**自动驾驶**、**医学影像**、**遥感**等领域持续取得更高性能，多目标检测与分割基准屡被刷新。而值得注意的是，数据集和评测方面也受到重视——NeurIPS专门设置了数据集与基准轨道，促进更可靠全面地评估CV算法[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=10)。CV领域的新进展体现了**更强的表征、更泛化的模型以及更逼真的生成**这三条主线。
- **强化学习（RL）**: 强化学习在2022–2024年保持着旺盛的研究活力，热点主要集中在**提高采样效率**和**拓展应用场景**上。一大方向是让智能体学习得**更快更高效**，为此研究者尝试了各种方案：利用**离线RL**和**模仿学习**在训练初期提供良好策略以克服探索难题，改进**信用分配**机制以在稀疏回报环境中更有效地归因行为贡献，以及借助预训练的**语言模型**等外部知识来指导策略学习[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Making agents more efficient learners,ended challenging settings)。例如，Facebook AI提出的方法将策略的控制因素与随机因素解耦，从信息论角度提高策略学习效率[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=prolific areas of research,offline learning%2C GFlowNets%2C and more)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=The adoption of latent variable,robustness capabilities in reinforcement learning)。又如，有研究让智能体阅读人类提供的**说明文档**来完成任务，结果显著提升了Atari游戏中的样本效率[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=diversity in multimodal target distributions)。另一个趋势是**跨模态赋能RL**：NeurIPS 2022 的 **MineDojo** 平台利用互联网的大规模Minecraft视频和维基知识，自动生成带标注的训练数据，让智能体在复杂的开放世界中学习，成功训练了在Minecraft中完成多种任务的通用智能体[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=2️⃣ MineDojo%3A Building Open,Scale Knowledge)。类似地，ICLR 2023 的研究“Read and Reap”表明利用游戏攻略等**文本信息**可以辅助RL代理更快地学会游戏策略[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=This paper explores the relationship,diversity in multimodal target distributions)。这些成果体现了**知识驱动的强化学习**的新方向。

强化学习的应用版图也在扩大。AlphaGo以来，强化学习已在博弈、控制等领域展示威力，近期则向**新兴领域**渗透：例如芯片设计中的元器件布局问题，Google 提出的深度RL方法MaskPlace已经能自动完成人工难以优化的芯片布局并超过人类专家[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=3️⃣ MaskPlace%3A Fast Chip Placement,via Reinforced Visual Representation Learning)；又如DeepMind的AlphaTensor利用RL成功发现了矩阵乘法的全新高效算法（发表在Nature 2022），将RL应用拓展到算法优化领域。此外，**生成流网络（GFlowNet）\**作为一种介于生成建模与RL之间的新框架，近年受到关注。GFlowNet通过将生成过程视为决策轨迹来高效采样多模态分布，ICLR等会议上涌现了一系列工作，将其用于化学分子结构生成并结合变分推断原理解释了其多样性采样优势[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-iclr-2023-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=4️⃣ GFlowNets and variational inference)。在\**理论性研究**方面，强化学习社区也更加注重**稳健性**和**可复现性**，提出了更严格的评测协议和挑战。一些工作着眼于证明算法的收敛性、样本复杂度，并将RL和控制理论、因果推理相结合，帮助我们更深刻地理解智能体学习的动力学过程[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Making agents more efficient learners,ended challenging settings)。

综上，近三年的深度学习研究在核心方法和应用上都呈现出蓬勃的发展态势：从新颖架构到训练算法，从理论分析到多领域应用，各个方向彼此交织。可以预见，这些研究热点将在未来继续演进，推动人工智能技术迈上新的台阶。

**参考来源：** 本文内容参考了 NeurIPS、ICLR、ICML 近年论文和综述博客中的资料，包括 Jakub Zavrel 等人在 Zeta Alpha 博客上的会议导览[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Expect to find a lot,tune large LMs)[zeta-alpha.com](https://www.zeta-alpha.com/post/a-guide-to-neurips-2022-10-topics-and-50-papers-you-shouldn-t-miss#:~:text=Granted%2C if anything deserves the,Google's Imagen%2C or Stable diffusion)等，以及各论文的公开摘要和报告[openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper#:~:text=This paper shows that masked,by 3x or)[nips.cc](https://nips.cc/virtual/2022/awards_detail#:~:text=We present Imagen%2C a text,27 on the)等。上述引用的文献和数据充分体现了2022–2024年深度学习与神经网络领域的研究热点和趋势。





Autoguidance 论文 4：用错误的版本指导扩散模型

[论文链接](https://openreview.net/forum?id=bg6fVPVs3s)
